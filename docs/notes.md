# Ideas on Visualization
1. A visual comparison between original images and the mix-up images generated by the mix-up augmentation.
2. Visualization on attention, provide insights into how the model focuses on different regions of the input
   - maybe use heatmap to visualize the attention?
3. Layer-wise feature visualization
4. Attention Evolution over Training
   - Potentially a series of heatmaps across epochs?
5. Prototype Visualization in Few-Shot Learning
   - Show how class prototypes evolve during training in your few-shot learning model.


# Dataset Description: Flowers102

The Flowers102 dataset is a comprehensive collection of flower images designed for image classification tasks. Key characteristics include:

1. **Size and Structure:**
   - Total images: 8,189
   - Classes: 102 different flower categories
   - Splits: Train (1,020 images), Validation (1,020 images), Test (6,149 images)

2. **Class Distribution:**
   - Train and Validation sets: Perfectly balanced with 10 images per class
   - Test set: Imbalanced, ranging from 20 to 238 images per class

3. **Features:**
   - High-quality images of flowers commonly found in the United Kingdom
   - Diverse in terms of scale, pose, and lighting conditions
   - Includes similar categories, challenging fine-grained classification

4. **Implications for Model Training:**
   - Balanced train/validation sets ideal for initial model training
   - Larger, imbalanced test set provides realistic performance evaluation
   - Suitable for developing robust flower classification models

5. **Baseline Model Performance:**
no pretrained (11/07 update)
| Model     | N-way | K-shot | Accuracy (%) | 95% CI (Â±) |
|-----------|--------|---------|--------------|------------|
| ResNet-50 | 5      | 1       | 52.52       | 2.98       |
| ResNet-50 | 5      | 5       | 65.24       | 2.54       |
| ResNet-50 | 5      | 8       | 66.30       | 3.32       |
| ResNet-50 | 10     | 1       | 49.00       | 1.81       |
| ResNet-50 | 10     | 5       | 53.30       | 2.15       |
| ResNet-50 | 10     | 8       | 56.50       | 2.53       |
| ResNet-50 | 20     | 1       | 26.93      | 0.99       |
| ResNet-50 | 20     | 5       | 37.91       | 1.11       |
| ResNet-50 | 20     | 8       | 41.47       | 1.81       |


# Custom Combined Dataset
Training set: 5752 images
Validation set: 1391 images
Test set: 1046 images

Training classes: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 40, 45, 47, 49, 50, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 75, 76, 77, 78, 80, 81, 82, 83, 84, 87, 88, 90, 92, 93, 95, 97, 98, 99, 101]
Average images per class (train): 81.0
Min images per class (train): 40
Max images per class (train): 258

Validation classes: [17, 24, 32, 41, 42, 43, 51, 56, 66, 72, 73, 79, 89, 94, 96]
Average images per class (val): 92.7
Min images per class (val): 41
Max images per class (val): 194

Test classes: [0, 18, 26, 38, 39, 44, 46, 48, 57, 70, 71, 74, 85, 86, 91, 100]
Average images per class (test): 65.4
Min images per class (test): 40
Max images per class (test): 120

# Report
1. Introduction
   - Problem overview
   - Motivation for few-shot learning
   - Project objectives

2. Background & Related Work
   - Traditional classification approaches
   - Few-shot learning methods
   - Prototypical Networks
   - Progressive training

3. Methodology
   - Baseline architectures implementation
   - Prototypical Network architecture
   - Progressive training strategy
   - Data augmentation techniques
   - Feature extraction and evaluation

4. Experiments
   - Dataset details
   - Training configurations
   - Evaluation protocols
   - Ablation studies:
     - Effect of progressive training
     - Impact of augmentations
     - Comparison across architectures

5. Results & Discussion
   - Comparative analysis
   - Few-shot learning performance
   - Progressive training benefits
   - Limitations and insights

6. Conclusion
   - Summary of findings
   - Future work
